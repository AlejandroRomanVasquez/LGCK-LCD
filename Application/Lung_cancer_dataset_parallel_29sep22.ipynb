{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1ac48ef6",
   "metadata": {},
   "source": [
    "# Preeliminaries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c80129ec",
   "metadata": {},
   "source": [
    "### Rpy2 package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "09e02c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext rpy2.ipython"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44107efd",
   "metadata": {},
   "source": [
    "### Importing R packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "99c78c59",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R[write to console]: Loading required package: Matrix\n",
      "\n",
      "R[write to console]: Loaded glmnet 4.1-4\n",
      "\n",
      "R[write to console]: \n",
      "Attaching package: ‘dplyr’\n",
      "\n",
      "\n",
      "R[write to console]: The following objects are masked from ‘package:stats’:\n",
      "\n",
      "    filter, lag\n",
      "\n",
      "\n",
      "R[write to console]: The following objects are masked from ‘package:base’:\n",
      "\n",
      "    intersect, setdiff, setequal, union\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <span>StrVector with 13 elements.</span>\n",
       "        <table>\n",
       "        <tbody>\n",
       "          <tr>\n",
       "          \n",
       "            <td>\n",
       "            'dplyr'\n",
       "            </td>\n",
       "          \n",
       "            <td>\n",
       "            'survival'\n",
       "            </td>\n",
       "          \n",
       "            <td>\n",
       "            'glmnet'\n",
       "            </td>\n",
       "          \n",
       "            <td>\n",
       "            ...\n",
       "            </td>\n",
       "          \n",
       "            <td>\n",
       "            'datasets'\n",
       "            </td>\n",
       "          \n",
       "            <td>\n",
       "            'methods'\n",
       "            </td>\n",
       "          \n",
       "            <td>\n",
       "            'base'\n",
       "            </td>\n",
       "          \n",
       "          </tr>\n",
       "        </tbody>\n",
       "        </table>\n",
       "        "
      ],
      "text/plain": [
       "<rpy2.robjects.vectors.StrVector object at 0x7fdf19072280> [RTYPES.STRSXP]\n",
       "R classes: ('character',)\n",
       "['dplyr', 'survival', 'glmnet', 'Matrix', ..., 'utils', 'datasets', 'methods', 'base']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%R library(latentcor)\n",
    "%R library(glmnet)\n",
    "%R library(survival)\n",
    "%R library(dplyr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c00d949",
   "metadata": {},
   "source": [
    "### Importing Python libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8571c51a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "import numpy as np\n",
    "from timeit import default_timer as timer\n",
    "import math\n",
    "\n",
    "\n",
    "#For parallel computing\n",
    "import multiprocessing\n",
    "from joblib import Parallel, delayed\n",
    "#Number of cores\n",
    "num_cores = multiprocessing.cpu_count()\n",
    "jobs=num_cores-1\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "#knockpy (knockoffs)\n",
    "import knockpy\n",
    "from knockpy.knockoff_filter import KnockoffFilter\n",
    "from knockpy.knockoff_stats import data_dependent_threshhold\n",
    "\n",
    "#GGlasso (graphical Lasso)\n",
    "from gglasso.problem import glasso_problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0fc798db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the package rpy2\n",
    "import rpy2\n",
    "import rpy2.robjects as robjects\n",
    "from rpy2.robjects.packages import importr\n",
    "from rpy2.robjects import r, pandas2ri\n",
    "from rpy2.robjects.conversion import localconverter\n",
    "\n",
    "# import R's packages\n",
    "base = importr('base')\n",
    "glmnet = importr('glmnet')\n",
    "dplyr = importr('dplyr')\n",
    "survival = importr('survival')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03a4df3e",
   "metadata": {},
   "source": [
    "### Auxiliary functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae79bcb0",
   "metadata": {},
   "source": [
    "#### Python functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "081bbf7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to make selections\n",
    "def make_selections(W, fdr):\n",
    "    \"\"\"\" Calculate data dependent threshhold and selections\n",
    "    returns a np.ndarray\n",
    "    \n",
    "    Parameters \n",
    "    ---------- \n",
    "    W : np.ndarray \n",
    "    fdr : float\n",
    "    \"\"\"  \n",
    "    \n",
    "    threshold = data_dependent_threshhold(W=W, fdr=fdr)\n",
    "    selected_flags = (W >= threshold).astype(\"float32\")\n",
    "    return selected_flags\n",
    "\n",
    "\n",
    "def lasso_glmnet_lambda_min(x):\n",
    "  \"\"\"\" Find the tuning lambda using the R package glmnet \n",
    "  \n",
    "  Returns a robjects.vectors.FloatVector\n",
    "  \n",
    "  Parameters \n",
    "  ---------- \n",
    "  x : pandas.DataFrame  \n",
    "  \"\"\"    \n",
    "    \n",
    "  #Convertion of the pandas dataframe to a R dataframe  \n",
    "  sim = x\n",
    "  with localconverter(robjects.default_converter + pandas2ri.converter):\n",
    "    r_sim = robjects.conversion.py2rpy(sim)\n",
    "  robjects.globalenv[\"r_sim\"] = r_sim\n",
    "  \n",
    "  #Loading R libraries  \n",
    "  base = importr('base')\n",
    "  glmnet = importr('glmnet')\n",
    "  dplyr = importr('dplyr')\n",
    "  survival = importr('survival')\n",
    "\n",
    "  #Fitting the Cox’s proportional hazards model employing glmnet\n",
    "  robjects.r(''' \n",
    "        X <- r_sim %>% select(-c(\"Pat_Died\", \"Pat_Overall_Survival_Months\"))\n",
    "        X_matrix <- as.matrix(X)\n",
    "        y <- r_sim %>% select(c(\"Pat_Died\", \"Pat_Overall_Survival_Months\"))\n",
    "        y_surv <- Surv(y$Pat_Overall_Survival_Months,y$Pat_Died)\n",
    "        cvfit <- cv.glmnet(X_matrix, y_surv, alpha=1, family = \"cox\", type.measure = \"C\", nfolds = 5, standardize = TRUE)\n",
    "        lambda_min_r <- as.numeric(cvfit$lambda.min)\n",
    "        ''')\n",
    "  #Tuning lambda\n",
    "  lambda_min = robjects.globalenv['lambda_min_r']  \n",
    "  \n",
    "  return lambda_min  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa0ace31",
   "metadata": {},
   "source": [
    "#### R functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "00847404",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "\n",
    "#Transformation to get the corresponding latent normal variable for each original ordinal variable\n",
    "transformation_to_get_latent_normal_variable <- function(original_variable){\n",
    "     \n",
    "    \n",
    "  var_table <- table(original_variable) # Table object to obtain the levels of the ordinal variable\n",
    "  n_levels <- dim(var_table) #Levels of the original ordinal variable\n",
    "  n <- sum(var_table) #Number of observations\n",
    "  \n",
    "  if (n_levels > 3) \n",
    "        stop(\"Ordinal variables with more than 3 levels must be considered continuous, \n",
    "              because latentcor estimation is limited to binary or ternary ordinal variables\")  \n",
    "    \n",
    "    \n",
    "  #Condition when the original ordinal variable has two levels  \n",
    "  if(n_levels==2){\n",
    "    Xj_1 <- as.numeric(var_table[2])/n \n",
    "    fCj_1 <- qnorm(1-Xj_1) #Transformed cutoffs (latent normal level)\n",
    "    nj_1 <- (abs(fCj_1-(-3))/2)+(-3) #Middle point of the interval ( fCj_0=-inf, fCj_1), where -inf is replace by -3  \n",
    "    nj_2 <- (abs(3-fCj_1)/2) + fCj_1 #Middle point of the interval ( fCj_1, fCj_2=inf ), where inf is replace by 3  \n",
    " \n",
    "    #The latent Gaussian transformed value is chosen as the middle point of the interval ( fCj_i, fCj_{i+1} ). \n",
    "    #The extreme points -inf and inf were replace for -3 and 3, respectively.\n",
    "    transformed_variable <- original_variable\n",
    "    transformed_variable[original_variable==as.numeric(names(var_table)[1])]= nj_1\n",
    "    transformed_variable[original_variable==as.numeric(names(var_table)[2])]= nj_2\n",
    "  }\n",
    "  #Condition when the original ordinal variable has three levels    \n",
    "  else{\n",
    "    Xj_1 <- as.numeric(var_table[2]+var_table[3])/n  \n",
    "    fCj_1 <- qnorm(1-Xj_1) #Transformed cutoffs (latent normal level)\n",
    "    nj_1 <- (abs(fCj_1-(-3))/2)+(-3) #Middle point of the interval ( fCj_0=-inf, fCj_1 ), where -inf is replace by -3  \n",
    "    Xj_2 <- as.numeric(var_table[3])/n  \n",
    "    fCj_2 <- qnorm(1-Xj_2 ) #Transformed cutoffs (latent normal level)\n",
    "    nj_2 <- (abs(fCj_2-fCj_1)/2)+(fCj_1) #Middle point of the interval ( fCj_1, fCj_2 )  \n",
    "    nj_3 <- (abs(3-fCj_2)/2) + fCj_2 #Middle point of the interval ( fCj_2, fCj_3=inf ), where inf is replace by 3.  \n",
    " \n",
    "  \n",
    "    #The latent Gaussian transformed value is chosen as the middle point of the interval ( fCj_i,fCj_{i+1} ). \n",
    "    #The extreme points -inf and inf were replace for -3 and 3, respectively.\n",
    "    transformed_variable <- original_variable\n",
    "    transformed_variable[original_variable==as.numeric(names(var_table)[1])] = nj_1\n",
    "    transformed_variable[original_variable==as.numeric(names(var_table)[2])] = nj_2\n",
    "    transformed_variable[original_variable==as.numeric(names(var_table)[3])] = nj_3\n",
    "  } \n",
    "\n",
    "return(transformed_variable)\n",
    "}\n",
    "\n",
    "\n",
    "#Transformation to obtain the orginal ordinal variable from the latent Gaussian knockoff\n",
    "transformation_to_get_original_variable <- function(original_variable, normal_variable){\n",
    "\n",
    "  var_table <- table(original_variable) #Table object to obtain the levels of the original ordinal variable\n",
    "  n_levels <- dim(var_table) #Levels of the original ordinal variable\n",
    "  n <- sum(var_table) #Number of observations \n",
    "  original_varible_unique_values <- sort(unique(original_variable)) #Unique values of the original ordinal variable\n",
    "  ordinal_variable <- rep(0,length(normal_variable))\n",
    "    \n",
    "  \n",
    "  if (n_levels > 3) \n",
    "      stop(\"Ordinal variables with more than 3 levels must be considered continuous, \n",
    "              because latentcor estimation is limited to binary or ternary ordinal variables\") \n",
    "    \n",
    "  #Condition when the original ordinal variable has two levels  \n",
    "  if(n_levels==2){\n",
    "    Xj_1 <- as.numeric(var_table[2])/n\n",
    "    fCj_1 <- qnorm(1-Xj_1)  #Transformed cutoffs (latent normal level)\n",
    "      \n",
    "    #Ordinal_variable assignation depending on the transformed cutoffs\n",
    "    ordinal_variable[normal_variable<=fCj_1] <- original_varible_unique_values[1]  \n",
    "    ordinal_variable[normal_variable>fCj_1] <- original_varible_unique_values[2]  \n",
    "\n",
    "  }\n",
    "  #Condition when the original ordinal variable has three levels    \n",
    "  else {\n",
    "    Xj_1 <- as.numeric(var_table[2]+var_table[3])/n  \n",
    "    fCj_1 <- qnorm(1-Xj_1) #Transformed cutoffs (latent normal level)\n",
    "    Xj_2 <- as.numeric(var_table[3])/n\n",
    "    fCj_2 <- qnorm(1-Xj_2 ) #Transformed cutoffs (latent normal level) \n",
    "      \n",
    "    #Ordinal_variable assignation depending on the trnsformed cutoffs  \n",
    "    ordinal_variable[normal_variable<=fCj_1] <- original_varible_unique_values[1]  \n",
    "    ordinal_variable[normal_variable>fCj_1 & normal_variable<=fCj_2] <- original_varible_unique_values[2]  \n",
    "    ordinal_variable[normal_variable>fCj_2] <- original_varible_unique_values[3]  \n",
    "   \n",
    "    }\n",
    "return(ordinal_variable)    \n",
    "}    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "99de3f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "\n",
    "#Function to identify if the variable is continuous(con) or ordinal (ord)\n",
    "column_type_identification <- function(col){ \n",
    "  if(length(unique(col)) < 4)\n",
    "  {type<-\"ord\"}\n",
    "  else\n",
    "  {type<-\"con\"} \n",
    "  return(type)\n",
    "}    \n",
    "\n",
    "\n",
    "#Function to identify if the variable is continuous(con), binary (bin) or ternary (ter)\n",
    "latentcor_type_identification <- function(col) { \n",
    "  if(length(unique(col)) == 2)\n",
    "  {type<-\"bin\"}\n",
    "  else if (length(unique(col)) == 3)\n",
    "  {type<-\"ter\"}\n",
    "  else\n",
    "  {type<-\"con\"} \n",
    "  return(type) \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72d0e779",
   "metadata": {},
   "source": [
    "### Parameter configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "23828a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initial time\n",
    "tii = timer()\n",
    "\n",
    "\n",
    "n_cv = 5  #Cross validation folds\n",
    "M = 200 #Runs for stabilizing the lasso against CV fold assignation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73d1f419",
   "metadata": {},
   "source": [
    "# Loading the Lung cancer dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9cc8065e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Importing the csv file (307 rows and 5005 columns)\n",
    "Lung_data_complete = pd.read_csv(\"Patients_final_5003.csv\")\n",
    "\n",
    "#Encoding for binary variables\n",
    "Lung_data_complete['Pat_Gender'] = np.where(Lung_data_complete['Pat_Gender']==\"M\",0,1)\n",
    "Lung_data_complete['Pat_Stage_red'] = np.where(Lung_data_complete['Pat_Stage_red']==\"I_II\",0,1)\n",
    "\n",
    "\n",
    "#Removing NA's and nan's from the dataframe \n",
    "Lung_data_complete = Lung_data_complete.dropna(axis=0, how='any')\n",
    "#15 observations are removed (less than 5%) \n",
    "\n",
    "\n",
    "#4 observations that have a survival time equal to zero, which causes a problem when fitting the Cox-lasso model.\n",
    "#Therefore, these values are modified to have a survival time of 1 day (1/30)\n",
    "Lung_data_complete.loc[Lung_data_complete.Pat_Overall_Survival_Months == 0, \"Pat_Overall_Survival_Months\"] = 0.033 \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc8dc1b9",
   "metadata": {},
   "source": [
    "### Previous step that filters the most variable genes in terms of their variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "273886fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Notes: \n",
    "#1) In the Lung_data data frame, the gene-expression column order is from the most variable to the less variable, \n",
    "#in terms of their variance. \n",
    "#2) The Lung_data contains the most 5000 expressed genes of a total of 20,356 genes of the\n",
    "# genomic dataset from the research of Rousseaux et al.(2013) located in the Lung Cancer Explorer (LCE) database \n",
    "# http://lce.biohpc.swmed.edu/.\n",
    "\n",
    "#Number of most expressed gene selected: \n",
    "gen_p = 289\n",
    "\n",
    "#Reduce dataframe with the most expressed genes given by gen_p \n",
    "#(there are 3 clinical variables and 2 variables associated to survival time and event type)\n",
    "Lung_data = Lung_data_complete.iloc[:,0: gen_p + 3 +2]\n",
    "\n",
    "#From Python to R\n",
    "%R -i Lung_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33f2f804",
   "metadata": {},
   "source": [
    "### Computing the censoring rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f765b70f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] 31.85\n"
     ]
    }
   ],
   "source": [
    "%%R\n",
    "\n",
    "Lung_data \n",
    "Censoring <- round(100*as.numeric(table(Lung_data$Pat_Died)[1]/length(Lung_data$Pat_Died)),2)\n",
    "print(Censoring)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4adc3da0",
   "metadata": {},
   "source": [
    "# Applying the Cox's PH model with Lasso penalization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "199f8ac7",
   "metadata": {},
   "source": [
    "### Stabilizing the lasso against CV (Roberts and Nowak, 2014)\n",
    "Fitting the penalized regression model  M times  to get M different values of the tuning parameter lambda."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "50542915",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time (min) taken to run the parallel computing 3.1005\n"
     ]
    }
   ],
   "source": [
    "ti = timer() #Initial time\n",
    "\n",
    "ls_Lung_data = list(range(M)) #List of pandas dataframes needed for the parallel processing\n",
    "for i in range(M):\n",
    "  ls_Lung_data[i] = Lung_data\n",
    "\n",
    "\n",
    "#Parallel code with Joblib\n",
    "ls_lambdas = Parallel(n_jobs=jobs)(delayed(lasso_glmnet_lambda_min)(x) for x in ls_Lung_data)\n",
    "\n",
    "time_parallel_computing = timer() - ti #Final time of parallel computing\n",
    "print('Time (min) taken to run the parallel computing',round(time_parallel_computing/60,4))\n",
    "\n",
    "\n",
    "#Transforming the list to a numpy array\n",
    "lambdas = np.array(ls_lambdas)\n",
    "\n",
    "#From python to R\n",
    "%R -i lambdas "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5276ca32",
   "metadata": {},
   "source": [
    "### Creating matrices: X and y_surv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2daad519",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.21e+02, 0.00e+00],\n",
       "       [1.10e+01, 1.00e+00],\n",
       "       [5.70e+01, 1.00e+00],\n",
       "       [4.30e+01, 1.00e+00],\n",
       "       [9.50e+01, 1.00e+00],\n",
       "       [3.40e+01, 1.00e+00],\n",
       "       [1.20e+01, 0.00e+00],\n",
       "       [3.30e+01, 1.00e+00],\n",
       "       [2.40e+01, 0.00e+00],\n",
       "       [2.00e+02, 0.00e+00],\n",
       "       [8.00e+01, 1.00e+00],\n",
       "       [1.21e+02, 0.00e+00],\n",
       "       [2.10e+01, 1.00e+00],\n",
       "       [8.60e+01, 1.00e+00],\n",
       "       [1.20e+01, 1.00e+00],\n",
       "       [1.95e+02, 1.00e+00],\n",
       "       [6.80e+01, 0.00e+00],\n",
       "       [5.20e+01, 1.00e+00],\n",
       "       [7.00e+01, 1.00e+00],\n",
       "       [1.15e+02, 0.00e+00],\n",
       "       [7.20e+01, 1.00e+00],\n",
       "       [1.18e+02, 0.00e+00],\n",
       "       [1.04e+02, 1.00e+00],\n",
       "       [5.00e+00, 1.00e+00],\n",
       "       [2.18e+02, 0.00e+00],\n",
       "       [8.70e+01, 0.00e+00],\n",
       "       [8.50e+01, 0.00e+00],\n",
       "       [5.10e+01, 0.00e+00],\n",
       "       [1.34e+02, 0.00e+00],\n",
       "       [3.60e+01, 1.00e+00],\n",
       "       [5.40e+01, 0.00e+00],\n",
       "       [3.40e+01, 1.00e+00],\n",
       "       [2.28e+02, 1.00e+00],\n",
       "       [2.00e+01, 1.00e+00],\n",
       "       [5.80e+01, 0.00e+00],\n",
       "       [2.90e+01, 1.00e+00],\n",
       "       [6.40e+01, 0.00e+00],\n",
       "       [1.02e+02, 0.00e+00],\n",
       "       [8.00e+00, 1.00e+00],\n",
       "       [7.10e+01, 1.00e+00],\n",
       "       [8.90e+01, 1.00e+00],\n",
       "       [1.31e+02, 0.00e+00],\n",
       "       [1.01e+02, 0.00e+00],\n",
       "       [1.70e+02, 0.00e+00],\n",
       "       [2.50e+01, 1.00e+00],\n",
       "       [8.80e+01, 0.00e+00],\n",
       "       [8.40e+01, 0.00e+00],\n",
       "       [1.16e+02, 0.00e+00],\n",
       "       [4.40e+01, 1.00e+00],\n",
       "       [1.08e+02, 1.00e+00],\n",
       "       [5.50e+01, 0.00e+00],\n",
       "       [2.00e+00, 1.00e+00],\n",
       "       [5.50e+01, 0.00e+00],\n",
       "       [1.11e+02, 1.00e+00],\n",
       "       [7.60e+01, 1.00e+00],\n",
       "       [4.60e+01, 1.00e+00],\n",
       "       [1.75e+02, 1.00e+00],\n",
       "       [2.03e+02, 0.00e+00],\n",
       "       [5.90e+01, 0.00e+00],\n",
       "       [7.40e+01, 1.00e+00],\n",
       "       [1.24e+02, 1.00e+00],\n",
       "       [1.99e+02, 0.00e+00],\n",
       "       [6.20e+01, 0.00e+00],\n",
       "       [1.39e+02, 1.00e+00],\n",
       "       [5.20e+01, 0.00e+00],\n",
       "       [2.50e+01, 1.00e+00],\n",
       "       [3.10e+01, 1.00e+00],\n",
       "       [9.00e+01, 1.00e+00],\n",
       "       [1.70e+01, 1.00e+00],\n",
       "       [4.00e+01, 1.00e+00],\n",
       "       [1.10e+01, 1.00e+00],\n",
       "       [2.20e+02, 0.00e+00],\n",
       "       [4.50e+01, 1.00e+00],\n",
       "       [8.50e+01, 0.00e+00],\n",
       "       [1.13e+02, 0.00e+00],\n",
       "       [1.20e+01, 1.00e+00],\n",
       "       [8.10e+01, 0.00e+00],\n",
       "       [5.60e+01, 0.00e+00],\n",
       "       [6.90e+01, 0.00e+00],\n",
       "       [5.20e+01, 1.00e+00],\n",
       "       [7.20e+01, 0.00e+00],\n",
       "       [1.40e+01, 1.00e+00],\n",
       "       [1.30e+01, 1.00e+00],\n",
       "       [1.00e+00, 1.00e+00],\n",
       "       [2.56e+02, 0.00e+00],\n",
       "       [3.30e-02, 1.00e+00],\n",
       "       [1.75e+02, 0.00e+00],\n",
       "       [8.40e+01, 1.00e+00],\n",
       "       [4.90e+01, 0.00e+00],\n",
       "       [3.80e+01, 1.00e+00],\n",
       "       [1.50e+02, 1.00e+00],\n",
       "       [2.80e+01, 1.00e+00],\n",
       "       [1.24e+02, 1.00e+00],\n",
       "       [9.90e+01, 0.00e+00],\n",
       "       [1.27e+02, 1.00e+00],\n",
       "       [5.30e+01, 1.00e+00],\n",
       "       [8.00e+01, 0.00e+00],\n",
       "       [1.80e+01, 1.00e+00],\n",
       "       [1.17e+02, 0.00e+00],\n",
       "       [6.80e+01, 1.00e+00],\n",
       "       [1.22e+02, 0.00e+00],\n",
       "       [5.60e+01, 0.00e+00],\n",
       "       [5.70e+01, 1.00e+00],\n",
       "       [1.77e+02, 0.00e+00],\n",
       "       [4.00e+01, 1.00e+00],\n",
       "       [1.20e+01, 1.00e+00],\n",
       "       [1.60e+01, 1.00e+00],\n",
       "       [1.37e+02, 0.00e+00],\n",
       "       [5.90e+01, 0.00e+00],\n",
       "       [2.16e+02, 0.00e+00],\n",
       "       [1.75e+02, 1.00e+00],\n",
       "       [8.90e+01, 0.00e+00],\n",
       "       [8.90e+01, 1.00e+00],\n",
       "       [6.10e+01, 0.00e+00],\n",
       "       [3.20e+01, 1.00e+00],\n",
       "       [6.50e+01, 0.00e+00],\n",
       "       [1.23e+02, 0.00e+00],\n",
       "       [1.29e+02, 0.00e+00],\n",
       "       [2.00e+00, 1.00e+00],\n",
       "       [1.30e+01, 1.00e+00],\n",
       "       [6.20e+01, 0.00e+00],\n",
       "       [1.40e+01, 1.00e+00],\n",
       "       [1.40e+01, 1.00e+00],\n",
       "       [1.34e+02, 0.00e+00],\n",
       "       [8.00e+01, 0.00e+00],\n",
       "       [3.30e-02, 1.00e+00],\n",
       "       [1.10e+01, 1.00e+00],\n",
       "       [1.00e+02, 0.00e+00],\n",
       "       [5.10e+01, 0.00e+00],\n",
       "       [3.30e+01, 1.00e+00],\n",
       "       [1.30e+01, 1.00e+00],\n",
       "       [1.75e+02, 0.00e+00],\n",
       "       [2.20e+01, 1.00e+00],\n",
       "       [1.07e+02, 1.00e+00],\n",
       "       [9.90e+01, 1.00e+00],\n",
       "       [2.10e+01, 1.00e+00],\n",
       "       [1.72e+02, 1.00e+00],\n",
       "       [6.30e+01, 0.00e+00],\n",
       "       [1.20e+01, 1.00e+00],\n",
       "       [1.70e+01, 1.00e+00],\n",
       "       [6.00e+01, 1.00e+00],\n",
       "       [1.40e+01, 1.00e+00],\n",
       "       [1.40e+01, 1.00e+00],\n",
       "       [1.10e+01, 1.00e+00],\n",
       "       [1.07e+02, 1.00e+00],\n",
       "       [2.00e+00, 1.00e+00],\n",
       "       [2.80e+01, 1.00e+00],\n",
       "       [2.00e+01, 1.00e+00],\n",
       "       [9.10e+01, 1.00e+00],\n",
       "       [1.30e+01, 1.00e+00],\n",
       "       [1.30e+01, 1.00e+00],\n",
       "       [2.40e+01, 1.00e+00],\n",
       "       [9.10e+01, 0.00e+00],\n",
       "       [8.70e+01, 1.00e+00],\n",
       "       [1.40e+01, 1.00e+00],\n",
       "       [3.00e+00, 1.00e+00],\n",
       "       [1.40e+01, 1.00e+00],\n",
       "       [5.60e+01, 0.00e+00],\n",
       "       [3.20e+01, 1.00e+00],\n",
       "       [3.10e+01, 1.00e+00],\n",
       "       [6.00e+00, 1.00e+00],\n",
       "       [8.50e+01, 0.00e+00],\n",
       "       [8.50e+01, 1.00e+00],\n",
       "       [1.84e+02, 0.00e+00],\n",
       "       [1.55e+02, 0.00e+00],\n",
       "       [1.23e+02, 0.00e+00],\n",
       "       [1.79e+02, 1.00e+00],\n",
       "       [1.19e+02, 0.00e+00],\n",
       "       [2.04e+02, 0.00e+00],\n",
       "       [5.30e+01, 0.00e+00],\n",
       "       [4.00e+00, 1.00e+00],\n",
       "       [2.30e+01, 1.00e+00],\n",
       "       [1.70e+01, 1.00e+00],\n",
       "       [1.03e+02, 1.00e+00],\n",
       "       [2.80e+01, 1.00e+00],\n",
       "       [1.70e+01, 1.00e+00],\n",
       "       [1.10e+01, 1.00e+00],\n",
       "       [1.90e+01, 1.00e+00],\n",
       "       [1.40e+01, 1.00e+00],\n",
       "       [3.00e+01, 1.00e+00],\n",
       "       [7.70e+01, 0.00e+00],\n",
       "       [2.00e+00, 1.00e+00],\n",
       "       [1.40e+02, 0.00e+00],\n",
       "       [1.10e+01, 1.00e+00],\n",
       "       [4.00e+00, 1.00e+00],\n",
       "       [6.00e+00, 1.00e+00],\n",
       "       [5.40e+01, 1.00e+00],\n",
       "       [8.00e+00, 1.00e+00],\n",
       "       [1.00e+01, 1.00e+00],\n",
       "       [1.21e+02, 0.00e+00],\n",
       "       [1.11e+02, 0.00e+00],\n",
       "       [1.05e+02, 0.00e+00],\n",
       "       [1.15e+02, 0.00e+00],\n",
       "       [1.02e+02, 1.00e+00],\n",
       "       [4.20e+01, 1.00e+00],\n",
       "       [5.90e+01, 1.00e+00],\n",
       "       [6.60e+01, 0.00e+00],\n",
       "       [2.44e+02, 0.00e+00],\n",
       "       [2.23e+02, 0.00e+00],\n",
       "       [1.57e+02, 0.00e+00],\n",
       "       [1.75e+02, 0.00e+00],\n",
       "       [2.30e+01, 1.00e+00],\n",
       "       [7.80e+01, 0.00e+00],\n",
       "       [6.70e+01, 0.00e+00],\n",
       "       [1.80e+02, 0.00e+00],\n",
       "       [5.20e+01, 1.00e+00],\n",
       "       [5.50e+01, 1.00e+00],\n",
       "       [1.93e+02, 1.00e+00],\n",
       "       [2.30e+01, 1.00e+00],\n",
       "       [2.05e+02, 0.00e+00],\n",
       "       [2.30e+01, 1.00e+00],\n",
       "       [4.00e+00, 1.00e+00],\n",
       "       [1.30e+01, 1.00e+00],\n",
       "       [6.70e+01, 1.00e+00],\n",
       "       [1.25e+02, 1.00e+00],\n",
       "       [2.20e+01, 1.00e+00],\n",
       "       [2.04e+02, 0.00e+00],\n",
       "       [2.60e+01, 1.00e+00],\n",
       "       [1.30e+01, 1.00e+00],\n",
       "       [4.20e+01, 1.00e+00],\n",
       "       [1.79e+02, 1.00e+00],\n",
       "       [4.80e+01, 1.00e+00],\n",
       "       [5.00e+01, 1.00e+00],\n",
       "       [3.00e+00, 0.00e+00],\n",
       "       [8.00e+00, 1.00e+00],\n",
       "       [1.88e+02, 0.00e+00],\n",
       "       [2.00e+00, 1.00e+00],\n",
       "       [9.00e+00, 1.00e+00],\n",
       "       [2.90e+01, 1.00e+00],\n",
       "       [9.10e+01, 0.00e+00],\n",
       "       [8.30e+01, 0.00e+00],\n",
       "       [1.30e+01, 1.00e+00],\n",
       "       [1.00e+01, 1.00e+00],\n",
       "       [4.00e+01, 1.00e+00],\n",
       "       [7.60e+01, 1.00e+00],\n",
       "       [2.70e+01, 1.00e+00],\n",
       "       [9.00e+00, 1.00e+00],\n",
       "       [6.30e+01, 1.00e+00],\n",
       "       [5.40e+01, 1.00e+00],\n",
       "       [1.40e+01, 1.00e+00],\n",
       "       [1.10e+01, 1.00e+00],\n",
       "       [1.43e+02, 1.00e+00],\n",
       "       [2.60e+01, 1.00e+00],\n",
       "       [2.10e+01, 1.00e+00],\n",
       "       [9.00e+00, 1.00e+00],\n",
       "       [1.34e+02, 1.00e+00],\n",
       "       [3.30e-02, 1.00e+00],\n",
       "       [2.30e+01, 1.00e+00],\n",
       "       [3.40e+01, 1.00e+00],\n",
       "       [5.00e+00, 1.00e+00],\n",
       "       [5.20e+01, 1.00e+00],\n",
       "       [1.70e+01, 1.00e+00],\n",
       "       [1.10e+01, 1.00e+00],\n",
       "       [3.40e+01, 1.00e+00],\n",
       "       [3.00e+00, 1.00e+00],\n",
       "       [2.00e+00, 1.00e+00],\n",
       "       [8.00e+00, 1.00e+00],\n",
       "       [3.30e-02, 1.00e+00],\n",
       "       [2.70e+01, 1.00e+00],\n",
       "       [4.50e+01, 1.00e+00],\n",
       "       [1.00e+02, 1.00e+00],\n",
       "       [8.80e+01, 1.00e+00],\n",
       "       [7.00e+00, 1.00e+00],\n",
       "       [3.00e+00, 1.00e+00],\n",
       "       [1.00e+00, 1.00e+00],\n",
       "       [4.00e+00, 1.00e+00],\n",
       "       [2.06e+02, 0.00e+00],\n",
       "       [1.04e+02, 1.00e+00],\n",
       "       [7.00e+00, 1.00e+00],\n",
       "       [1.40e+02, 1.00e+00],\n",
       "       [9.00e+00, 1.00e+00],\n",
       "       [2.30e+01, 1.00e+00],\n",
       "       [1.10e+01, 1.00e+00],\n",
       "       [1.10e+01, 1.00e+00],\n",
       "       [1.74e+02, 1.00e+00],\n",
       "       [8.00e+00, 1.00e+00],\n",
       "       [1.05e+02, 1.00e+00],\n",
       "       [2.90e+01, 1.00e+00],\n",
       "       [1.18e+02, 1.00e+00],\n",
       "       [7.00e+00, 1.00e+00],\n",
       "       [8.10e+01, 1.00e+00],\n",
       "       [1.80e+01, 1.00e+00],\n",
       "       [6.00e+00, 1.00e+00],\n",
       "       [1.18e+02, 1.00e+00],\n",
       "       [6.00e+00, 1.00e+00],\n",
       "       [1.11e+02, 0.00e+00],\n",
       "       [1.90e+01, 1.00e+00],\n",
       "       [1.16e+02, 0.00e+00],\n",
       "       [8.00e+00, 1.00e+00],\n",
       "       [2.00e+01, 1.00e+00],\n",
       "       [6.00e+00, 1.00e+00],\n",
       "       [2.00e+00, 1.00e+00]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#4 observations that have a survival time equal to zero, which causes a problem when fitting the Cox-lasso model.\n",
    "#Therefore, these values are modified to have a survival time of 1 day (1/30)\n",
    "%R Lung_data$Pat_Overall_Survival_Months[Lung_data$Pat_Overall_Survival_Months==0] <- 0.033\n",
    "\n",
    "#Matrix generation\n",
    "%R X <- Lung_data %>% select(-c(\"Pat_Died\", \"Pat_Overall_Survival_Months\"))\n",
    "%R X_matrix <- as.matrix(X)\n",
    "%R y <- Lung_data %>% select(c(\"Pat_Died\", \"Pat_Overall_Survival_Months\"))\n",
    "%R y_surv <- Surv(y$Pat_Overall_Survival_Months,y$Pat_Died)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf08450d",
   "metadata": {},
   "source": [
    "### Fitting the Cox’s proportional hazards model with Lasso (original predictors X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2187237f",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Pat_Age Pat_Stage_red         51297          5055          6696 \n",
      " 1.937963e-02  5.087666e-01 -2.199087e-03 -8.438380e-06  3.046971e-02 \n",
      "         1428         28781          6590        283120          3495 \n",
      "-1.453308e-01 -2.690735e-02 -1.480740e-01  3.333601e-02 -3.848062e-02 \n",
      "         9787 \n",
      " 2.795149e-01 \n"
     ]
    }
   ],
   "source": [
    "%%R\n",
    "\n",
    "#The 50-percentile corresponds to the usual Cox-lasso\n",
    "lambda50 <- as.numeric(quantile(lambdas,probs=0.5)) \n",
    "\n",
    "#Fitting the final model with the tunned lambda\n",
    "fit <- glmnet(X_matrix,y_surv,alpha = 1, lambda = lambda50, family = \"cox\", standardize = TRUE)\n",
    "\n",
    "fit_coef <- coef(fit)\n",
    "\n",
    "#Showing the variables selected (coefficients different to zero)\n",
    "print(fit_coef[fit_coef[,1]!=0,])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60b53a55",
   "metadata": {},
   "source": [
    "# Applying the Model-X knockoff methodology"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f66fc78b",
   "metadata": {},
   "source": [
    "## 1) knockoff construction using the LGCK procedure\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc7e9576",
   "metadata": {},
   "source": [
    "### Data preparation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d3d567f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Design matrix X\n",
    "data_X = Lung_data.drop(['Pat_Died','Pat_Overall_Survival_Months'], axis=1)\n",
    "\n",
    "#Necessary elements  to calculate the truncated empirical cumulative distribution funcion (ECDF) estimator\n",
    "n = data_X.shape[0] #Number of observations\n",
    "p = data_X.shape[1] #Number of covariates\n",
    "delta_n = 1/( (4*n**(1/4))*math.sqrt(math.pi*math.log(n)) )\n",
    "\n",
    "#From Python to R\n",
    "%R -i data_X\n",
    "%R -i p\n",
    "%R -i delta_n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0ea1543",
   "metadata": {},
   "source": [
    "### Step 1 of the LGCK procedure: Estimation of the latent correlation matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "15199229",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.        , -0.11320615, -0.11700009, ..., -0.08648349,\n",
       "         0.03196515, -0.03861371],\n",
       "       [-0.11320615,  1.        ,  0.02135272, ...,  0.13807362,\n",
       "        -0.10099819,  0.11955142],\n",
       "       [-0.11700009,  0.02135272,  1.        , ..., -0.21852877,\n",
       "         0.36934779, -0.37179449],\n",
       "       ...,\n",
       "       [-0.08648349,  0.13807362, -0.21852877, ...,  1.        ,\n",
       "        -0.19845127,  0.33284737],\n",
       "       [ 0.03196515, -0.10099819,  0.36934779, ..., -0.19845127,\n",
       "         1.        , -0.2492608 ],\n",
       "       [-0.03861371,  0.11955142, -0.37179449, ...,  0.33284737,\n",
       "        -0.2492608 ,  1.        ]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Column identification\n",
    "%R column_type <- apply(data_X, MARGIN = 2, FUN = column_type_identification)\n",
    "%R latentcor_type <- apply(data_X, MARGIN = 2, FUN = latentcor_type_identification)\n",
    "\n",
    "#Latencor estimation\n",
    "%R latentcor_hat <- latentcor(data_X, type=latentcor_type, method=\"original\")$R\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bdbc769",
   "metadata": {},
   "source": [
    "### Step 2 of the LGCK procedure: Estimation of the precision matrix of the latent correlation matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bd771c62",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ADMM terminated after 23 iterations with status: optimal.\n",
      "ADMM terminated after 12 iterations with status: optimal.\n",
      "ADMM terminated after 29 iterations with status: optimal.\n",
      "ADMM terminated after 12 iterations with status: optimal.\n",
      "ADMM terminated after 12 iterations with status: optimal.\n",
      "ADMM terminated after 25 iterations with status: optimal.\n",
      "ADMM terminated after 172 iterations with status: optimal.\n",
      "ADMM terminated after 12 iterations with status: optimal.\n",
      "ADMM terminated after 11 iterations with status: optimal.\n",
      "ADMM terminated after 9 iterations with status: optimal.\n",
      "ADMM terminated after 254 iterations with status: optimal.\n",
      "ADMM terminated after 226 iterations with status: optimal.\n",
      "ADMM terminated after 123 iterations with status: optimal.\n",
      "ADMM terminated after 135 iterations with status: optimal.\n",
      "ADMM terminated after 135 iterations with status: optimal.\n",
      "ADMM terminated after 153 iterations with status: optimal.\n",
      "ADMM terminated after 182 iterations with status: optimal.\n",
      "ADMM terminated after 208 iterations with status: optimal.\n",
      "ADMM terminated after 231 iterations with status: optimal.\n",
      "ADMM terminated after 258 iterations with status: optimal.\n",
      "ADMM terminated after 308 iterations with status: optimal.\n",
      "ADMM terminated after 381 iterations with status: optimal.\n",
      "ADMM terminated after 471 iterations with status: optimal.\n",
      "ADMM terminated after 533 iterations with status: optimal.\n",
      "ADMM terminated after 589 iterations with status: optimal.\n",
      "ADMM terminated after 721 iterations with status: optimal.\n",
      "ADMM terminated after 662 iterations with status: optimal.\n",
      "ADMM terminated after 773 iterations with status: optimal.\n",
      "ADMM terminated after 592 iterations with status: optimal.\n",
      "ADMM terminated after 551 iterations with status: optimal.\n",
      "ADMM terminated after 449 iterations with status: optimal.\n",
      "ADMM terminated after 287 iterations with status: optimal.\n",
      "ADMM terminated after 196 iterations with status: optimal.\n"
     ]
    }
   ],
   "source": [
    "#From Python to R\n",
    "%R -o latentcor_hat \n",
    "\n",
    "#Instantiate the  glasso_problem\n",
    "P = glasso_problem(S=latentcor_hat, N=n, reg_params = {'lambda1': 0.05}, latent = False, do_scaling = False)\n",
    "\n",
    "# Next, do model selection by solving the problem on a range of lambda values.\n",
    "lambda1_range = np.logspace(1, -5, 30)\n",
    "modelselect_params = {'lambda1_range': lambda1_range}\n",
    "P.model_selection(modelselect_params = modelselect_params, method = 'eBIC', gamma = 0.1)\n",
    "\n",
    "#Precision and Sigma matrices\n",
    "sol = P.solution.precision_\n",
    "Sigma_hat = np.linalg.inv(sol)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4268b4b",
   "metadata": {},
   "source": [
    "### Step 3 of the LGCK procedure: Nonparametric transformation strategy to obtain marginal normality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "342960cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "\n",
    "#Matrices for ECDF and X_norm_hat (contains the sample Gaussian Knockoffs)\n",
    "X_ecdf <- data_X \n",
    "X_norm_hat <- data_X\n",
    "\n",
    "#Empirical cumulative distribution function\n",
    "for(i in 1:p) {  \n",
    "    if(column_type[i]==\"con\"){ \n",
    "        X_ecdf[,i] <- as.vector(ecdf(data_X[,i])(data_X[,i])) \n",
    "    }\n",
    "}\n",
    "\n",
    "#Truncation for computing the Winsorized ECDF\n",
    "for(i in 1:p) {   \n",
    "    if(column_type[i]==\"con\"){ \n",
    "        X_ecdf[,i][ X_ecdf[,i] < delta_n] <- delta_n \n",
    "    }\n",
    "}\n",
    "for(i in 1:p) {   \n",
    "    if(column_type[i]==\"con\"){ \n",
    "        X_ecdf[,i][ X_ecdf[,i] > (1-delta_n)] <- 1-delta_n \n",
    "    }\n",
    "}   \n",
    "\n",
    "#Getting normal margins for continuous variables\n",
    "for(i in 1:p) {   \n",
    "    if(column_type[i]==\"con\"){ \n",
    "        X_norm_hat[,i] <- as.vector(qnorm( X_ecdf[,i] ) )\n",
    "    }\n",
    "}\n",
    "  \n",
    "#Transformation to get the corresponding latent normal variable for each ordinal variable\n",
    "for(i in 1:p) {   \n",
    "    if(column_type[i]==\"ord\"){ \n",
    "        X_norm_hat[,i] <- transformation_to_get_latent_normal_variable(data_X[,i])\n",
    "    }\n",
    "}  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90395524",
   "metadata": {},
   "source": [
    "### Step 4 of the LGCK procedure. Sampling Gaussian knockoffs using the MRV approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c1e0d066",
   "metadata": {},
   "outputs": [],
   "source": [
    "#From R to Python\n",
    "%R -o X_norm_hat\n",
    "\n",
    "#set seed\n",
    "np.random.seed(1)\n",
    "\n",
    "#Instantiating an object of the class GaussianSampler for sampling \n",
    "#Gaussian knockoffs using the estimated Sigma_hat and the method mvr\n",
    "Gaussian_sampler_hat = knockpy.knockoffs.GaussianSampler(X_norm_hat.to_numpy(), mu=None,\n",
    "                                                           Sigma=Sigma_hat,\n",
    "                                                           method='mvr', verbose=False)\n",
    "#Samplign the Gaussian Knockoffs\n",
    "Xk_norm_hat = Gaussian_sampler_hat.sample_knockoffs() \n",
    "\n",
    "\n",
    "#Creating a dataframes from the array that contains the Gaussian Knockoffs\n",
    "df_Xk_norm_hat = pd.DataFrame(Xk_norm_hat)\n",
    "\n",
    "#From Python to R\n",
    "%R -i df_Xk_norm_hat\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ee72403",
   "metadata": {},
   "source": [
    "### Step 5 of the LGCK procedure. Reversing transformation to obtain the non-Gaussian Knockoffs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "367c40a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dataframe to save the transformations\n",
    "%R df_Xk_hat <- df_Xk_norm_hat\n",
    "\n",
    "#Transformation to obtain the original continuous variable from the Gaussian knockoff  \n",
    "%R for(i in 1:p) {   if(column_type[i]==\"con\"){ df_Xk_hat[,i] <- as.vector(quantile(data_X[,i], probs=pnorm(df_Xk_norm_hat[,i]), type=8)) }}\n",
    "#Transformation to obtain the orginal ordinal variable from the latent Gaussian knockoff\n",
    "%R for(i in 1:p) {   if(column_type[i]==\"ord\"){ df_Xk_hat[,i] <- transformation_to_get_original_variable(original_variable=data_X[,i], normal_variable=df_Xk_norm_hat[,i])}}\n",
    "\n",
    "#From R to Python\n",
    "%R -o df_Xk_hat\n",
    "df_Xk_hat.reset_index(drop=True, inplace=True)\n",
    "\n",
    "#Creating the names for the variables in Xk\n",
    "columns_names = list(data_X.columns)\n",
    "k_columns_names = ['K_'+ str(name) for name in columns_names]\n",
    "df_Xk_hat.columns = k_columns_names\n",
    "\n",
    "#Creating the dataset (X, Xk) (original variables + knockoffs)\n",
    "data_X.reset_index(drop=True, inplace=True)\n",
    "data_X_Xk = pd.concat([data_X, df_Xk_hat], axis=1)\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d87eb10",
   "metadata": {},
   "source": [
    "## 2) Knockoff statistic estimation "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca9da288",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Creating the Lung_data_Xk dataframe (Lung_data + Knockoffs Xk)¶\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "853e891e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Selecting the survival time and event indicator\n",
    "y_surv = Lung_data.filter(['Pat_Died','Pat_Overall_Survival_Months'], axis=1)\n",
    "y_surv.reset_index(drop=True, inplace=True)\n",
    "\n",
    "#New dataset with the knockoffs\n",
    "Lung_data_Xk = pd.concat([y_surv, data_X_Xk], axis=1)\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b0ece2e",
   "metadata": {},
   "source": [
    "### Stabilizing the lasso against CV (Roberts and Nowak, 2014)\n",
    "Fitting the penalized regression model  M times to get M different values of the tuning parameter lambda."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "19ab59dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time (min) taken to run the parallel computing 1.2165\n"
     ]
    }
   ],
   "source": [
    "ti = timer() #Initial time\n",
    "\n",
    "ls_Lung_data_Xk = list(range(M)) #List of pandas data frames needed for the parallel processing\n",
    "for i in range(M):\n",
    "  ls_Lung_data_Xk[i] = Lung_data_Xk\n",
    "\n",
    "\n",
    "#Parallel code with Joblib\n",
    "ls_lambdas_Xk = Parallel(n_jobs=jobs)(delayed(lasso_glmnet_lambda_min)(x) for x in ls_Lung_data_Xk)\n",
    "\n",
    "\n",
    "time_parallel_computing = timer() - ti #Final time of parallel computing\n",
    "print('Time (min) taken to run the parallel computing',round(time_parallel_computing/60,4))\n",
    "\n",
    "\n",
    "#Transforming the list to a numpy array\n",
    "lambdas_Xk = np.array(ls_lambdas_Xk)\n",
    "\n",
    "#From Python to R\n",
    "%R -i lambdas_Xk \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1da1cb7",
   "metadata": {},
   "source": [
    "### Creating the matrix (X,Xk) (Original variables X + Knockoffs Xk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "79ec9994",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.        , 60.        ,  0.        , ...,  0.26363052,\n",
       "        -0.88803707, -0.46701719],\n",
       "       [ 0.        , 52.        ,  1.        , ...,  1.6066931 ,\n",
       "        -0.3855968 , -0.4967244 ],\n",
       "       [ 0.        , 66.        ,  0.        , ...,  0.89208975,\n",
       "        -0.76690606,  1.32898096],\n",
       "       ...,\n",
       "       [ 0.        , 51.        ,  0.        , ..., -1.21061369,\n",
       "         1.87386177, -0.80302497],\n",
       "       [ 0.        , 60.        ,  1.        , ..., -0.92949962,\n",
       "        -0.16210037, -0.25827246],\n",
       "       [ 0.        , 66.        ,  0.        , ...,  0.95160549,\n",
       "        -0.73107787, -0.56504696]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#From Python to R\n",
    "%R -i Lung_data_Xk\n",
    "\n",
    "#Matrix generation\n",
    "%R X_Xk <- Lung_data_Xk %>% select(-c(\"Pat_Died\", \"Pat_Overall_Survival_Months\"))\n",
    "%R X_Xk_matrix <- as.matrix(X_Xk)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "656f4f8f",
   "metadata": {},
   "source": [
    "### Fitting the Cox’s proportional hazards model with Lasso (Original variables X + Knockoffs Xk) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "538fb5c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "\n",
    "#The 50-percentile corresponds to the usual Cox-lasso\n",
    "lambda50_Xk <- as.numeric(quantile(lambdas_Xk,probs=0.5))\n",
    "\n",
    "#Fitting the final model with the tunned lambda\n",
    "fit_LCGK <- glmnet(X_Xk_matrix, y_surv, alpha = 1, lambda =lambda50_Xk, family = \"cox\", standardize = TRUE)\n",
    "\n",
    "fit_LCGK_coef <- coef(fit_LCGK)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69a3a45a",
   "metadata": {},
   "source": [
    "###  Computing the variable importance statistic (Z) and the knockoff feature statistic (Wj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "316c2642",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transforming the sparse matrix to a vector\n",
    "%R fit_LCGK_coef_vec <- as.vector(fit_LCGK_coef)\n",
    "\n",
    "#From R to Python\n",
    "%R -o fit_LCGK_coef_vec\n",
    "\n",
    "#Variable importance statistic\n",
    "Z = fit_LCGK_coef_vec\n",
    "\n",
    "#Knockoff statistic (Wj)\n",
    "pair_W = np.abs(Z[0:p]) - np.abs(Z[p:])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14239cc7",
   "metadata": {},
   "source": [
    "## 3) Data-dependent threshold calculation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a2934bbd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold for knockoffs \n",
      "0.004189289911246587\n",
      "Number of non-zero knockoff coefficients: 8.0\n"
     ]
    }
   ],
   "source": [
    "#Target false discovery rate\n",
    "FDR=0.25\n",
    "\n",
    "#Data-dependent threshold calculation\n",
    "threshold = data_dependent_threshhold(W=pair_W, fdr= FDR)\n",
    "print(\"Threshold for knockoffs \")\n",
    "print(threshold)\n",
    "rejections = make_selections(W=pair_W, fdr= FDR)\n",
    "\n",
    "#Number of selections (rejections of the null hypothesis of Y independent of Xj given X-j)\n",
    "Number_Rejections_knockoff_hat = rejections.sum()\n",
    "print(\"Number of non-zero knockoff coefficients: {}\".format(Number_Rejections_knockoff_hat))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "411848ec",
   "metadata": {},
   "source": [
    "# Results of selected features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c90b9724",
   "metadata": {},
   "source": [
    "### Selected variables (LGCK-LCD procedure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d91901a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Pat_Age', 'Pat_Stage_red', '6696', '1428', '6590', '283120',\n",
       "       '3495', '9787'], dtype=object)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_X.columns.values[rejections==1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a52161a",
   "metadata": {},
   "source": [
    "### Selected variables (Cox-lasso)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9434b6d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Pat_Age Pat_Stage_red         51297          5055          6696 \n",
      " 1.937963e-02  5.087666e-01 -2.199087e-03 -8.438380e-06  3.046971e-02 \n",
      "         1428         28781          6590        283120          3495 \n",
      "-1.453308e-01 -2.690735e-02 -1.480740e-01  3.333601e-02 -3.848062e-02 \n",
      "         9787 \n",
      " 2.795149e-01 \n",
      "[1] 11\n"
     ]
    }
   ],
   "source": [
    "%%R\n",
    "#Showing the variables selected (coefficients different to zero)\n",
    "print(fit_coef[fit_coef[,1]!=0,])\n",
    "print(length(fit_coef[fit_coef[,1]!=0,]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "58aa785b",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features (p): 292\n",
      "Time (min) taken to run all is: 5.7812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R[write to console]: There were 50 or more warnings (use warnings() to see the first 50)\n",
      "R[write to console]: \n",
      "\n",
      "R[write to console]: There were 50 or more warnings (use warnings() to see the first 50)\n",
      "R[write to console]: \n",
      "\n",
      "R[write to console]: There were 50 or more warnings (use warnings() to see the first 50)\n",
      "R[write to console]: \n",
      "\n",
      "R[write to console]: There were 50 or more warnings (use warnings() to see the first 50)\n",
      "R[write to console]: \n",
      "\n",
      "R[write to console]: There were 50 or more warnings (use warnings() to see the first 50)\n",
      "R[write to console]: \n",
      "\n",
      "R[write to console]: There were 50 or more warnings (use warnings() to see the first 50)\n",
      "R[write to console]: \n",
      "\n",
      "R[write to console]: There were 50 or more warnings (use warnings() to see the first 50)\n",
      "R[write to console]: \n",
      "\n",
      "R[write to console]: There were 50 or more warnings (use warnings() to see the first 50)\n",
      "R[write to console]: \n",
      "\n",
      "R[write to console]: There were 50 or more warnings (use warnings() to see the first 50)\n",
      "R[write to console]: \n",
      "\n",
      "R[write to console]: There were 50 or more warnings (use warnings() to see the first 50)\n",
      "R[write to console]: \n",
      "\n",
      "R[write to console]: There were 50 or more warnings (use warnings() to see the first 50)\n",
      "R[write to console]: \n",
      "\n",
      "R[write to console]: There were 50 or more warnings (use warnings() to see the first 50)\n",
      "R[write to console]: \n",
      "\n",
      "R[write to console]: There were 50 or more warnings (use warnings() to see the first 50)\n",
      "R[write to console]: \n",
      "\n",
      "R[write to console]: There were 50 or more warnings (use warnings() to see the first 50)\n",
      "R[write to console]: \n",
      "\n",
      "R[write to console]: There were 50 or more warnings (use warnings() to see the first 50)\n",
      "R[write to console]: \n",
      "\n",
      "R[write to console]: There were 50 or more warnings (use warnings() to see the first 50)\n",
      "R[write to console]: \n",
      "\n",
      "R[write to console]: There were 50 or more warnings (use warnings() to see the first 50)\n",
      "R[write to console]: \n",
      "\n",
      "R[write to console]: There were 50 or more warnings (use warnings() to see the first 50)\n",
      "R[write to console]: \n",
      "\n",
      "R[write to console]: There were 50 or more warnings (use warnings() to see the first 50)\n",
      "R[write to console]: \n",
      "\n",
      "R[write to console]: There were 50 or more warnings (use warnings() to see the first 50)\n",
      "R[write to console]: \n",
      "\n",
      "R[write to console]: There were 50 or more warnings (use warnings() to see the first 50)\n",
      "R[write to console]: \n",
      "\n",
      "R[write to console]: There were 50 or more warnings (use warnings() to see the first 50)\n",
      "R[write to console]: \n",
      "\n",
      "R[write to console]: There were 50 or more warnings (use warnings() to see the first 50)\n",
      "R[write to console]: \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Number of features (p):',p) #Number of features of the initial dataset: lung_data\n",
    "\n",
    "tff = timer()\n",
    "print('Time (min) taken to run all is:',round((tff-tii)/60,4)) #Computing time"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
